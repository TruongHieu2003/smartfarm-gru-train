import pandas as pd
import numpy as np
import json
import os
import time
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import GRU, Dense, Input
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.losses import MeanSquaredError
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import firebase_admin
from firebase_admin import credentials, db
import smtplib
from email.mime.text import MIMEText
from pytz import timezone

def send_email_notification(message):
    try:
        smtp_user = os.environ.get("EMAIL_USER")
        smtp_pass = os.environ.get("EMAIL_PASSWORD")
        receivers = os.environ.get("Email_Receiver")

        if not smtp_user or not smtp_pass or not receivers:
            print("‚ö†Ô∏è Thi·∫øu th√¥ng tin SMTP.")
            return

        receiver_list = [email.strip() for email in receivers.split(",")]

        subject = "SmartFarm - Tr·∫°ng th√°i c·∫≠p nh·∫≠t d·ªØ li·ªáu"
        body = f"{message}\n\nTh·ªùi gian: {datetime.now(timezone('Asia/Ho_Chi_Minh')).strftime('%H:%M %d/%m/%Y')}"

        msg = MIMEText(body)
        msg["Subject"] = subject
        msg["From"] = smtp_user
        msg["To"] = ", ".join(receiver_list)

        server = smtplib.SMTP("smtp.gmail.com", 587)
        server.starttls()
        server.login(smtp_user, smtp_pass)
        server.sendmail(smtp_user, receiver_list, msg.as_string())
        server.quit()
        print("üìß ƒê√£ g·ª≠i email th√¥ng b√°o")
    except Exception as e:
        print("‚ùå L·ªói g·ª≠i mail:", e)

def run_training_and_forecast():
    print("\nüîÅ B·∫Øt ƒë·∫ßu ki·ªÉm tra v√† hu·∫•n luy·ªán...")

    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    json_str = os.environ.get("GOOGLE_SERVICE_JSON")
    sheet_url = os.environ.get("SHEET_URL")

    if not json_str or not sheet_url:
        print("‚ùå Thi·∫øu GOOGLE_SERVICE_JSON ho·∫∑c SHEET_URL")
        return

    try:
        google_key = json.loads(json_str)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(google_key, scope)
        client = gspread.authorize(creds)
        sheet = client.open_by_url(sheet_url.strip())
        worksheet = sheet.worksheet("DATA")
        data = pd.DataFrame(worksheet.get_all_records())
    except Exception as e:
        print("‚ùå L·ªói truy c·∫≠p Google Sheets:", e)
        return

    data.columns = data.columns.str.strip()

    required_columns = ["NG√ÄY", "GI·ªú", "temperature", "humidity", "soil_moisture", "wind", "rain"]
    if not all(col in data.columns for col in required_columns):
        print("‚ùå D·ªØ li·ªáu thi·∫øu c·ªôt c·∫ßn thi·∫øt:", set(required_columns) - set(data.columns))
        return

    try:
        data['timestamp'] = pd.to_datetime(data['NG√ÄY'] + ' ' + data['GI·ªú'], format='%d/%m/%Y %H:%M:%S')
    except Exception as e:
        print("‚ùå L·ªói chuy·ªÉn ƒë·ªïi th·ªùi gian:", e)
        return

    data = data.sort_values('timestamp')
    data.rename(columns={
        'temperature': 'temp', 'humidity': 'humid', 'soil_moisture': 'soil',
        'wind': 'wind', 'rain': 'rain'
    }, inplace=True)

    # T√≠ch l≈©y d·ªØ li·ªáu
    if os.path.exists("training_data.csv"):
        try:
            old_data = pd.read_csv("training_data.csv", parse_dates=["timestamp"])
            data = pd.concat([old_data, data])
        except Exception as e:
            print("‚ö†Ô∏è L·ªói ƒë·ªçc training_data.csv:", e)

    data.drop_duplicates(subset="timestamp", keep="last", inplace=True)
    data = data.sort_values("timestamp").reset_index(drop=True)

    # Ki·ªÉm tra th·ªùi gian
    saved_timestamp = None
    if os.path.exists("last_timestamp.json"):
        try:
            with open("last_timestamp.json", "r") as f:
                saved_timestamp = pd.to_datetime(json.load(f)["last_timestamp"])
        except Exception as e:
            print("‚ö†Ô∏è L·ªói ƒë·ªçc last_timestamp.json:", e)

    latest_timestamp = data["timestamp"].iloc[-1]
    if saved_timestamp is not None and latest_timestamp <= saved_timestamp:
        print("üü° KH√îNG c√≥ d·ªØ li·ªáu m·ªõi.")
        send_email_notification("üü° KH√îNG c√≥ d·ªØ li·ªáu m·ªõi ƒë·ªÉ hu·∫•n luy·ªán.")
        return

    features = ['temp', 'humid', 'soil', 'wind', 'rain']
    if data[features].isnull().any().any():
        print("‚ö†Ô∏è C√≥ gi√° tr·ªã thi·∫øu trong d·ªØ li·ªáu. Lo·∫°i b·ªè d√≤ng l·ªói.")
        data.dropna(subset=features, inplace=True)

    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data[features])

    model_path = "gru_weather_model.h5"
    window_size = 6

    if not os.path.exists(model_path):
        model = Sequential([
            Input(shape=(window_size, len(features))),
            GRU(units=64),
            Dense(len(features))
        ])
        model.compile(optimizer="adam", loss=MeanSquaredError())
    else:
        model = load_model(model_path, compile=False)
        model.compile(optimizer="adam", loss=MeanSquaredError())

    print("üü¢ C√≥ d·ªØ li·ªáu m·ªõi. ƒêang hu·∫•n luy·ªán...")
    X, y = [], []
    for i in range(len(scaled_data) - window_size):
        X.append(scaled_data[i:i + window_size])
        y.append(scaled_data[i + window_size])

    model.fit(np.array(X), np.array(y), epochs=100, batch_size=16,
              callbacks=[EarlyStopping(monitor="loss", patience=5)], verbose=0)
    model.save(model_path)

    data.to_csv("training_data.csv", index=False)
    with open("last_timestamp.json", "w") as f:
        json.dump({"last_timestamp": str(latest_timestamp)}, f)

    # D·ª± b√°o 24 gi·ªù ti·∫øp theo
    current_seq = scaled_data[-window_size:].copy()
    forecast = []
    for _ in range(24):
        x_input = current_seq.reshape(1, window_size, len(features))
        y_pred = model.predict(x_input, verbose=0)
        forecast.append(y_pred[0])
        current_seq = np.vstack([current_seq[1:], y_pred])

    forecast_original = scaler.inverse_transform(np.array(forecast))
    forecast_df = pd.DataFrame(forecast_original, columns=features).clip(lower=0).round(2)

    # T·∫°o th·ªùi gian d·ª± b√°o
    base_time = datetime.now(timezone("Asia/Ho_Chi_Minh")) + timedelta(days=1)
    base_time = base_time.replace(hour=0, minute=0)
    forecast_df.insert(0, "time", [(base_time + timedelta(hours=i)).strftime("%d/%m/%Y %H:%M") for i in range(24)])

    # L∆∞u local
    forecast_df.to_json("latest_prediction.json", orient="records", indent=2)

    try:
        if not firebase_admin._apps:
            firebase_key = os.environ.get("FIREBASE_SERVICE_ACCOUNT_JSON")
            if not firebase_key:
                raise Exception("‚ùå FIREBASE_SERVICE_ACCOUNT_JSON is missing")
            firebase_key = json.loads(firebase_key)
            cred = credentials.Certificate(firebase_key)
            firebase_admin.initialize_app(cred, {
                "databaseURL": "https://smart-farm-6e42d-default-rtdb.firebaseio.com/"
            })

        db.reference("forecast/tomorrow").set(forecast_df.to_dict(orient="records"))
        print("üì° ƒê√£ c·∫≠p nh·∫≠t Firebase.")
    except Exception as e:
        print("‚ùå L·ªói c·∫≠p nh·∫≠t Firebase:", e)

    send_email_notification("üü¢ D·ª± b√°o m·ªõi ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† c·∫≠p nh·∫≠t.")
    print("‚úÖ XONG l√∫c", datetime.now(timezone("Asia/Ho_Chi_Minh")).strftime("%H:%M:%S %d/%m/%Y"))

if __name__ == "__main__":
    while True:
        run_training_and_forecast()
        time.sleep(300)
