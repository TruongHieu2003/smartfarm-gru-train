import pandas as pd
import numpy as np
import json
import os
import time
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import GRU, Dense, Input
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.losses import MeanSquaredError
import gspread
from google.oauth2.service_account import Credentials
import firebase_admin
from firebase_admin import credentials, db
import smtplib
from email.mime.text import MIMEText
from pytz import timezone

def send_email_notification(message):
    try:
        smtp_user = os.environ.get("EMAIL_USER")
        smtp_pass = os.environ.get("EMAIL_PASSWORD")
        receivers = os.environ.get("Email_Receiver")

        if not smtp_user or not smtp_pass or not receivers:
            print("‚ö†Ô∏è Thi·∫øu th√¥ng tin SMTP.")
            return

        receiver_list = [email.strip() for email in receivers.split(",")]

        subject = "SmartFarm - Tr·∫°ng th√°i c·∫≠p nh·∫≠t d·ªØ li·ªáu"
        body = f"{message}\n\nTh·ªùi gian: {datetime.now(timezone('Asia/Ho_Chi_Minh')).strftime('%H:%M %d/%m/%Y')}"

        msg = MIMEText(body)
        msg["Subject"] = subject
        msg["From"] = smtp_user
        msg["To"] = ", ".join(receiver_list)

        server = smtplib.SMTP("smtp.gmail.com", 587)
        server.starttls()
        server.login(smtp_user, smtp_pass)
        server.sendmail(smtp_user, receiver_list, msg.as_string())
        server.quit()
        print("üìß ƒê√£ g·ª≠i email th√¥ng b√°o")
    except Exception as e:
        print("‚ùå L·ªói g·ª≠i mail:", e)

def run_training_and_forecast():
    print("\nüîÅ B·∫Øt ƒë·∫ßu ki·ªÉm tra v√† hu·∫•n luy·ªán...\n")

    # üß™ Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng cho Google Sheets
    raw_json = os.environ.get("GOOGLE_SERVICE_JSON")
    if raw_json:
        # convert literal '\n' into actual newline
        raw_json = raw_json.replace('\\n', '\n')
    sheet_url = os.environ.get("SHEET_URL", "").strip()

    print("üîç Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng:")
    print("GOOGLE_SERVICE_JSON t·ªìn t·∫°i:", bool(raw_json))
    print("SHEET_URL:", sheet_url)

    if not raw_json or not sheet_url:
        print("‚ùå Thi·∫øu GOOGLE_SERVICE_JSON ho·∫∑c SHEET_URL")
        return

    # parse JSON v√† authorize gspread
    try:
        service_account_info = json.loads(raw_json)
        creds = Credentials.from_service_account_info(service_account_info)
        client = gspread.authorize(creds)
        print("‚úÖ GOOGLE_SERVICE_JSON h·ª£p l·ªá v√† authorized")
    except Exception as e:
        print("‚ùå L·ªói x·ª≠ l√Ω GOOGLE_SERVICE_JSON ho·∫∑c authorize:", e)
        return

    # L·∫•y d·ªØ li·ªáu t·ª´ Sheets
    try:
        sheet = client.open_by_url(sheet_url)
        worksheet = sheet.worksheet("DATA")
        data = pd.DataFrame(worksheet.get_all_records())
        print("‚úÖ L·∫•y d·ªØ li·ªáu t·ª´ Google Sheets th√†nh c√¥ng")
    except Exception as e:
        print("‚ùå L·ªói truy c·∫≠p Google Sheets:", e)
        return

    # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu...
    data.columns = data.columns.str.strip()
    required_columns = ["NG√ÄY", "GI·ªú", "temperature", "humidity", "soil_moisture", "wind", "rain"]
    if not all(col in data.columns for col in required_columns):
        missing = set(required_columns) - set(data.columns)
        print("‚ùå D·ªØ li·ªáu thi·∫øu c·ªôt c·∫ßn thi·∫øt:", missing)
        return

    try:
        data['timestamp'] = pd.to_datetime(
            data['NG√ÄY'] + ' ' + data['GI·ªú'],
            format='%d/%m/%Y %H:%M:%S'
        )
        print("‚úÖ ƒê√£ t·∫°o c·ªôt timestamp")
    except Exception as e:
        print("‚ùå L·ªói chuy·ªÉn ƒë·ªïi th·ªùi gian:", e)
        return

    data = data.sort_values('timestamp').reset_index(drop=True)
    data.rename(columns={
        'temperature': 'temp', 'humidity': 'humid',
        'soil_moisture': 'soil', 'wind': 'wind', 'rain': 'rain'
    }, inplace=True)

    # N·ªëi v·ªõi data c≈© n·∫øu c√≥
    if os.path.exists("training_data.csv"):
        try:
            old_data = pd.read_csv("training_data.csv", parse_dates=["timestamp"])
            data = pd.concat([old_data, data], ignore_index=True)
            print(f"üîÅ N·ªëi d·ªØ li·ªáu c≈©: {len(old_data)} + m·ªõi: {len(data)-len(old_data)}")
        except Exception as e:
            print("‚ö†Ô∏è L·ªói ƒë·ªçc training_data.csv:", e)

    data.drop_duplicates(subset="timestamp", keep="last", inplace=True)
    data = data.sort_values("timestamp").reset_index(drop=True)
    print("‚úÖ D·ªØ li·ªáu t·ªïng sau x·ª≠ l√Ω:", data.shape)

    # L·∫•y last_timestamp
    saved_ts = None
    if os.path.exists("last_timestamp.json"):
        try:
            with open("last_timestamp.json", "r") as f:
                saved_ts = pd.to_datetime(json.load(f)["last_timestamp"])
                print("üß™ L·∫ßn cu·ªëi hu·∫•n luy·ªán l√∫c:", saved_ts)
        except Exception as e:
            print("‚ö†Ô∏è L·ªói ƒë·ªçc last_timestamp.json:", e)

    latest_ts = data["timestamp"].iloc[-1]
    print("üÜï Timestamp m·ªõi nh·∫•t:", latest_ts)
    if saved_ts and latest_ts <= saved_ts:
        print("üü° KH√îNG c√≥ d·ªØ li·ªáu m·ªõi.")
        send_email_notification("üü° KH√îNG c√≥ d·ªØ li·ªáu m·ªõi ƒë·ªÉ hu·∫•n luy·ªán.")
        return

    # Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán
    features = ['temp', 'humid', 'soil', 'wind', 'rain']
    data.dropna(subset=features, inplace=True)
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(data[features])
    print("‚úÖ Scale d·ªØ li·ªáu:", scaled.shape)

    # X√¢y d·ª±ng ho·∫∑c load model
    model_path = "gru_weather_model.h5"
    window_size = 6
    if not os.path.exists(model_path):
        print("üì¶ T·∫°o m·ªõi GRU model...")
        model = Sequential([
            Input(shape=(window_size, len(features))),
            GRU(64),
            Dense(len(features))
        ])
        model.compile(optimizer="adam", loss=MeanSquaredError())
    else:
        print("üì¶ Load model hi·ªán c√≥...")
        model = load_model(model_path, compile=False)
        model.compile(optimizer="adam", loss=MeanSquaredError())

    # T·∫°o d·ªØ li·ªáu X,y
    X, y = [], []
    for i in range(len(scaled) - window_size):
        X.append(scaled[i:i+window_size])
        y.append(scaled[i+window_size])
    X, y = np.array(X), np.array(y)
    print(f"üìä D·ªØ li·ªáu hu·∫•n luy·ªán: X={X.shape}, y={y.shape}")

    # Hu·∫•n luy·ªán
    print("üü¢ Hu·∫•n luy·ªán model...")
    model.fit(
        X, y,
        epochs=100, batch_size=16,
        callbacks=[EarlyStopping(monitor="loss", patience=5)],
        verbose=0
    )
    model.save(model_path)
    print("‚úÖ L∆∞u model xong")

    # C·∫≠p nh·∫≠t training_data & last_timestamp
    data.to_csv("training_data.csv", index=False)
    with open("last_timestamp.json", "w") as f:
        json.dump({"last_timestamp": str(latest_ts)}, f)

    # D·ª± b√°o 24h ti·∫øp theo
    seq = scaled[-window_size:].copy()
    preds = []
    for _ in range(24):
        p = model.predict(seq.reshape(1, window_size, -1), verbose=0)[0]
        preds.append(p)
        seq = np.vstack([seq[1:], p])
    orig = scaler.inverse_transform(preds)
    df_fore = pd.DataFrame(orig, columns=features).clip(lower=0).round(2)

    # Th√™m c·ªôt time
    base = datetime.now(timezone("Asia/Ho_Chi_Minh")) + timedelta(days=1)
    base = base.replace(hour=0, minute=0)
    df_fore.insert(
        0, "time",
        [(base + timedelta(hours=i)).strftime("%d/%m/%Y %H:%M") for i in range(24)]
    )
    df_fore.to_json("latest_prediction.json", orient="records", indent=2)
    print("üìÅ L∆∞u d·ª± b√°o v√†o latest_prediction.json")

    # C·∫≠p nh·∫≠t Firebase
    try:
        if not firebase_admin._apps:
            raw_fb = os.environ.get("FIREBASE_SERVICE_ACCOUNT_JSON")
            if raw_fb:
                raw_fb = raw_fb.replace('\\n', '\n')
            if not raw_fb:
                raise ValueError("Missing FIREBASE_SERVICE_ACCOUNT_JSON")
            fb_info = json.loads(raw_fb)
            cred = credentials.Certificate(fb_info)
            firebase_admin.initialize_app(cred, {
                "databaseURL": "https://smart-farm-6e42d-default-rtdb.firebaseio.com/"
            })
        db.reference("forecast/tomorrow").set(df_fore.to_dict(orient="records"))
        print("üì° ƒê√£ c·∫≠p nh·∫≠t Firebase.")
    except Exception as e:
        print("‚ùå L·ªói c·∫≠p nh·∫≠t Firebase:", e)

    # G·ª≠i th√¥ng b√°o email
    send_email_notification("üü¢ D·ª± b√°o m·ªõi ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† c·∫≠p nh·∫≠t.")
    print("‚úÖ XONG l√∫c", datetime.now(timezone("Asia/Ho_Chi_Minh")).strftime("%H:%M:%S %d/%m/%Y"))

if __name__ == "__main__":
    while True:
        run_training_and_forecast()
        time.sleep(300)
